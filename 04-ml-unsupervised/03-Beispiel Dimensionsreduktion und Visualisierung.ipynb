{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b58bb8",
   "metadata": {},
   "source": [
    "# Beispiel Dimensionsreduktion und Datenvisualisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f23302",
   "metadata": {},
   "source": [
    "Um die Dimensionsreduktion ausprobieren zu können, schaust du dir am besten ein Beispiel an. Da du dir viele Dimensionen nur schwer vorstellen kannst, wirst du alles auf zwei Dimensionen reduzieren und intensiv mit Visualisierungen arbeiten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0cad60",
   "metadata": {},
   "source": [
    "## Das `digits`-Datenset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242559e",
   "metadata": {},
   "source": [
    "Hierzu nutzt du das `digits`-Datenset, das bereits in `scikit-learn` integriert ist. Dabei handelt es sich um handgeschriebene Ziffern. Die Bilder sind dabei auf 8\\*8 Pixel reduziert. Jeder Pixel kann Grauwerte von `0` bis `15` annehmen. Es sind insgesamt 1.797 Bilder.\n",
    "\n",
    "Das Datenset kannst du ganz einfach laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1d82a",
   "metadata": {},
   "source": [
    "Du könntest dir nun die Grauwerte anzeigen lassen, aber dabei kannst du nicht viel erkennen. Es ist einfacher, wenn du dir ein paar der Bilder ausgeben lässt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3037133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in [0, 200, 400, 600]:\n",
    "    print(digits.target[i])\n",
    "    plt.gray()\n",
    "    plt.matshow(digits.images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdefa530",
   "metadata": {},
   "source": [
    "Mit etwas Fantasie und aus größerer Entfernung kannst du die Ziffern erkennen.\n",
    "\n",
    "Nun konvertierst du die Daten in einen `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(digits[\"data\"], columns=digits[\"feature_names\"])\n",
    "df[\"class\"] = [digits[\"target_names\"][target] for target in digits[\"target\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c5c04",
   "metadata": {},
   "source": [
    "Du erkennst die Anzahl der Samples und die Features (`target` zählt nicht als Feature.\n",
    "\n",
    "Ein bisschen Statistik kann nicht schaden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19728082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31170b82",
   "metadata": {},
   "source": [
    "Die obere Zeile scheint nicht stark beschrieben zu sein, sonst kannst du nicht sehr viel erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81dff93",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb879ad",
   "metadata": {},
   "source": [
    "Als erstes probierst du PCA, also die Hauptkomponentenanalyse aus. Ein Charakteristikum der PCA sind die Eigenwerte. Anhand dieser kannst du entscheiden, auf wie viele Dimensionen du mehr oder weniger *gefahrlos* reduzieren kannst.\n",
    "\n",
    "Um alle Eigenwerte zu bestimmen, kannst du die Dimensionen gleich lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6726ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=digits[\"data\"].shape[1]).fit(digits[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf3bf3",
   "metadata": {},
   "source": [
    "Die Eigenwerte kannst du nun plotten. Der sog. Scree-Plot zeigt die, wie viele Dimensionen du benötigst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7ef3c",
   "metadata": {},
   "source": [
    "Das wären bei PCA schon sehr viele Dimensioenen, also sicher 40-50. Das hilft dir hier nicht viel weiter, also probierst du es mit zwei Dimensionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143bb875",
   "metadata": {},
   "source": [
    "In `scikit-learn` findet die Transformation immer mit der Methode `fit_transform` statt. Das Ergebnis überträgst du gleich in einen `DataFrame` und packst das Target noch mit dazu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(pca2.fit_transform(digits[\"data\"]), columns=[\"x\", \"y\"])\n",
    "pdf[\"target\"] = digits[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfcb62",
   "metadata": {},
   "source": [
    "Den so entstandenen `DataFrame` kannst du mit einem *Scatterplot* visualisieren. Leider verschiebt `matplotlib` die Skala etwas. Das lässt sich nur mit erheblichem Aufwand korrigieren und gehört eher in einen Visualisierungskurs. Also sei bitte vorsichtig, wenn du die Legende abliest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.plot.scatter(x='x', y='y', c=\"target\", figsize=(10,10), cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297bcf7",
   "metadata": {},
   "source": [
    "Manche Zahlen konnte PCA schon gut voneinander trennen, bei anderen hat das gar nicht geklappt und es gibt große Überlagerungen. Das Ergebnis ist nicht wirklich brauchbar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbbd30",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7efa8",
   "metadata": {},
   "source": [
    "Nun kennst du die Aufrufe von `scikit-learn` schon und kannst nach dem identischen Schema eine Dimensionsreduktion mit t-SNE durchführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76400938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne2 = TSNE(n_components=2, random_state=42)\n",
    "tdf = pd.DataFrame(tsne2.fit_transform(digits[\"data\"]), columns=[\"x\", \"y\"])\n",
    "tdf[\"target\"] = digits[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e5625",
   "metadata": {},
   "source": [
    "Das dauert eine Weile länger, ist das Ergebnis besser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4857d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.plot.scatter(x='x', y='y', c=tdf[\"target\"], figsize=(10,10), cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951dd6db",
   "metadata": {},
   "source": [
    "Das ist ein sehr großer Unterschied! Die einzelnen Ziifern sind sehr deutlich voneinander getrennt, nur die `1` tanzt etwas aus der Reihe. `3` und `9` überlappen sich leicht - das kann einer schlampigen Schrift zugeschrieben werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d90788",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eec9c3",
   "metadata": {},
   "source": [
    "PCA wird doch noch relativ häufig verwendet, t-SNE dagegen eher selten. Es ist langsamer und skaliert nicht gut. Außerdem funktioniert es ähnlich wie UMAP, das deutlich schneller ist. Das probierst du jetzt aus. Leider ist UMAP noch nicht in `scikit-learn` integriert, du musst es manuell installieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn[parametric_umap]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07046eff",
   "metadata": {},
   "source": [
    "Zum Glück ist der Aufruf aber sehr ähnlich (es erbt einige Klassen von `scikit-learn`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap2 = umap.UMAP(n_components=2, random_state=42)\n",
    "udf = pd.DataFrame(umap2.fit_transform(digits[\"data\"], ), columns=[\"x\", \"y\"])\n",
    "udf[\"target\"] = digits[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729aea38",
   "metadata": {},
   "source": [
    "Wie sieht das Ergrebnis hier aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.plot.scatter(x='x', y='y', c=\"target\", figsize=(10,10), cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ad29c",
   "metadata": {},
   "source": [
    "Die Daten sind noch deutlich besser separiert. In diesem Fall ist UMAP unser \"Sieger\". Das ist häufig so. UMAP ist in den meisten Fällen das heute beste Verfahren, um Dimensionen zu reduzieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcffac",
   "metadata": {},
   "source": [
    "## Dimensionreduktion als erster Schritt zum Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872967e",
   "metadata": {},
   "source": [
    "Häufig wirst du mit hochdimensionalen Daten arbeiten müssen. Das ist aber für viele Anwendungen nicht geschickt. Daher solltest du versuchen, die Dimensionen zu reduzieren oder zumindest zu überprüfen, ob das gut funktioniert. PCA ist immer einen Versuch wert, aber in echten Projekten wirst du sicher am häufigsten mit UMAP arbeiten.\n",
    "\n",
    "t-SNE ist hauptsächlich historisch interessant, weil es 2008 einen neuen Ansatz geboten hat. UMAP ist hier fast immer überlegen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
