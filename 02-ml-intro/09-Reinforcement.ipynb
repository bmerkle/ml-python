{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4634b809",
   "metadata": {},
   "source": [
    "# Lernen durch Verstärkung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1bad9",
   "metadata": {},
   "source": [
    "[Bestärkendes Lernen](https://de.wikipedia.org/wiki/Best%C3%A4rkendes_Lernen) oder sog. [Reinforcement Learning](https://de.wikipedia.org/wiki/Best%C3%A4rkendes_Lernen) unterscheidet sich substanziell von den anderen Lernverfahren, weil es kein Modell benötigt. Stattdessen verbirgt sich dahinter eine *Strategie* (oder unterschiedliche je nach Ansatz).\n",
    "\n",
    "Du wirst sehr viele komplexe Szenarien finden, in denen solche Lernverfahren eingesetzt werden können. Die Grundidee ist hingegen sehr einfach und lässt sich am besten an dem sog. [Multi-Armed Bandit](https://en.wikipedia.org/wiki/Multi-armed_bandit) erkunden.\n",
    "\n",
    "Stell dir dazu vor, dass du dich in einem Casino in Las Vegas befindest und 1000 Dollar zur Verfügung hast, die du gerne möglichst gewinnbringend an zehn [einarmigen Banditen](https://de.wikipedia.org/wiki/Spielautomat#Die_Anf%C3%A4nge) einsetzen möchtest. \n",
    "\n",
    "Die Spielautomaten funktionieren so, dass du einen Dollar einwirfst. Wenn du gewinnst, erhältst du zwei Dollar; wenn du verlierst, ist der Dollar weg.\n",
    "\n",
    "Für unser Beispiel gehst du davon aus, dass gesetzliche Beschränkungen den Casinobetreiber dazu zwingen, mit den Spielautomaten im Mittel *keinen Gewinn* erzielen zu dürfen.\n",
    "\n",
    "Du hast nun unterschiedliche Möglichkeiten, wie du vorgehen kannst:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f7abe",
   "metadata": {},
   "source": [
    "## Lösung durch *Exploration*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228f95f",
   "metadata": {},
   "source": [
    "Du kannst jetzt in jeden Spielautomaten 100 Dollar einwerfen und überprüfen, wie viel Geld du von jedem zurückbekommen hast. Damit hast du ein statistisch gutes Bild davon, welcher Spielautomat am besten funktioniert.\n",
    "\n",
    "Betrachte das nun an einem Beispiel. Du erzeugst zunächst zehn Spielautomaten mit unterschiedlichen Gewinnwahrscheinlichkeiten, die du *extra ungerecht* verteilst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba5fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def bandit(i):\n",
    "    threshold = (i*2+1)/20\n",
    "    if random.random() < threshold:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9694caa",
   "metadata": {},
   "source": [
    "Die Funktion `bandit()` liefert für die Spielautomaten mit den Nummern `0-9` jeweils einen Gewinn mit den Wahrscheinlichkeiten `5%`, `15%`, ..., `95%` zurück. Im Mittel sind das `50%`, es ist also *fair* (und wäre für den Casinobetreiber ein schlechtes Geschäft).\n",
    "\n",
    "Führe jetzt dein Experiment durch und stecke in jeden Automaten 100 Dollar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826b4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "money = np.array([0]*10)\n",
    "for b in range(10):\n",
    "    for d in range(100):\n",
    "        money[b] += bandit(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91419e05",
   "metadata": {},
   "source": [
    "Wie viel Geld hast du zurück bekommen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d580d7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(money)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a92d73",
   "metadata": {},
   "source": [
    "Das sieht für den Casinobetreiber doch gar nicht so schlecht aus, aber das liegt nur an der Statistik. Jetzt kannst du noch betrachten, welcher Automat dir wie viel Geld zurückgegeben hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdcecf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(money).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891f42c",
   "metadata": {},
   "source": [
    "Das war eine sog. *Explorationsstrategie*, weil du absolut in die Breite gearbeitet hast. Du weißt nun mit größtmöglicher statistischer Sicherheit, welcher Automat welche Gewinnwahrscheinlichkeit hat.\n",
    "\n",
    "Erkenntnistheoretisch ist das gut, aus wirtschaftlicher Sicht kannst du das aber besser machen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe46c33",
   "metadata": {},
   "source": [
    "## Lösung durch Ausbeutung (Exploitation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f257cad",
   "metadata": {},
   "source": [
    "Du kannst dir nun eine andere Strategie ausdenken. Zunächst wirfst du in jeden Automaten 10 Dollar und schaust, wie viel du zurück bekommst. Den Automaten, der dir am meisten zurückgibt, fütterst du überproportional mit mehr Geld.\n",
    "\n",
    "Um zu verhindern, dass ein \"schlechter\" Automat dir nur zufällig viel Geld zurückgegeben hat, gibst du auch den augenscheinlich schlechteren Automaten noch ein bisschen Geld. Du berechnest immer wieder die Gewinnquote und justierst die Wahrscheilichkeiten immer neu, mit denen du Geld in die Automaten steckst.\n",
    "\n",
    "Du startest mit der ersten Runde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53759b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "money = np.array([0]*10)\n",
    "coins = np.array([0]*10)\n",
    "for b in range(10):\n",
    "    for d in range(10):\n",
    "        money[b] += bandit(b)\n",
    "        coins[b] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfa959",
   "metadata": {},
   "source": [
    "Berechne nun den Erwartungswert für jeden Automaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615f4359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.4, 0.6, 0. , 1.6, 1.2, 1.2, 1.4, 1.6, 1.6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money/coins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e66ed4",
   "metadata": {},
   "source": [
    "In der nächsten Runde setzt du wieder 100 Dollar ein, allerdings verteilst du sie mehr an die Automaten, die dir mehr zurückgegeben haben. Dem \"schlechtesten\" Automaten gibst du einen Dollar, dem etwas besseren drei usw. Das ist der *Kern des Verfahrens*, nämlich die Strategie, wie du aus den bisherigen Erfahrungen die Belohnung verteilst.\n",
    "\n",
    "Bei zehn Automaten verteilst du damit wieder 100 Dollar - wie gewünscht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c983ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "for b in (money/coins).argsort():\n",
    "    for d in range(c):\n",
    "        money[b] += bandit(b)\n",
    "        coins[b] += 1\n",
    "    c += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99331d27",
   "metadata": {},
   "source": [
    "Das kannst du auch nochmal überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d595c616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62696898",
   "metadata": {},
   "source": [
    "Passt genau! Schau dir jetzt die Erwartungswerte an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed58ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30769231, 0.4       , 0.47058824, 0.18181818, 1.36      ,\n",
       "       1.15789474, 1.14285714, 1.47826087, 1.7037037 , 1.72413793])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money/coins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a31f4",
   "metadata": {},
   "source": [
    "Auch das sieht schon besser aus, zumindest die \"guten\" Automaten haben sich durchgesetzt.\n",
    "\n",
    "Du hast noch 800 Dollar zur Verfügung, daher kannst du das obige Verfahren einfach nochmal achtmal durchführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0bc697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(8):\n",
    "    c = 1\n",
    "    for b in (money/coins).argsort():\n",
    "        for d in range(c):\n",
    "            money[b] += bandit(b)\n",
    "            coins[b] += 1\n",
    "        c += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e208d1",
   "metadata": {},
   "source": [
    "Jetzt hast du 1000 Dollar verspielt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08c6858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765749b8",
   "metadata": {},
   "source": [
    "Bist du mit dieser Strategie erfolgreicher gewesen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05151faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(money)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789dc47",
   "metadata": {},
   "source": [
    "Absolut. Die Bank hast du noch nicht gesprengt, aber es ist schon mehr rausgekommen als du reingesteckt hast. Wie sehen die Erwartungswerte aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96838ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19354839, 0.37288136, 0.43478261, 0.4       , 0.89320388,\n",
       "       1.1047619 , 1.12396694, 1.41258741, 1.70552147, 1.91160221])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money/coins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f724180",
   "metadata": {},
   "source": [
    "Die Reihenfolge hat sich verbessert, stimmt aber noch nicht ganz. Bei der Exploration konntest du genauere Abschätzungen finden, bei der Ausbeutung aber mehr verdienen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6683e",
   "metadata": {},
   "source": [
    "Betrachte zuletzt noch, wie viel Geld du in welchen Automaten gesteckt hast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1b387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31,  59,  69,  25, 103, 105, 121, 143, 163, 181])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c6eac",
   "metadata": {},
   "source": [
    "## Sandkastenbeispiel für Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01716e79",
   "metadata": {},
   "source": [
    "Reinforcement Learning kann ziemlich komplex werden. Die grundsätzliche Strategie hast du mit diesem Beispiel verstanden. Und obwohl das Verfahren einfach, ja geradezu banal klingt, wird es häufig eingesetzt. \n",
    "\n",
    "Wenn du z.B. viel im Internet bestellst, bist du wahrscheinlich selbst schon *Opfer der Ausbeutung* geworden. Online-Shops verwenden den gleichen Prozess, um unterschiedliche Varianten des Bestellprozesses zu testen (sog. A/B-Tests). Der mit der höheren *Conversion Rate* wird dabei immer bevorzugt - genau wie in dem Beispiel oben."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
