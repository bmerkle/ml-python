{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLNMQgb20PsI"
   },
   "source": [
    "## Unüberwachte Lernverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duwHunbQ0PsJ"
   },
   "source": [
    "Unüberwachte Lernverfahren ermitteln die *intrinsische Struktur* von Daten. Sie benötigen keine Trainingsdaten und sind unvoreingenommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMtK448D0PsJ"
   },
   "source": [
    "### Iris-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJasAly30Prt"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJasAly30Prt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idf = pd.DataFrame(iris[\"data\"], columns=[\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\"])\n",
    "idf[\"target\"] = iris[\"target\"]\n",
    "idf[\"name\"] = [iris[\"target_names\"][target] for target in iris[\"target\"]]\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6K2L2bL0PsJ"
   },
   "source": [
    "Du kannst die Iris-Daten auch clustern. Die meisten Cluster-Algorithmen brauchen als Vorgabe die Anzahl der Cluster, so auch das hier verwendete `KMeans`. Versuche es erst mit einer \"falschen\" Anzahl an Clustern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfqo5DD10PsJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km5 = KMeans(n_clusters=5)\n",
    "km5.fit(iris['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esyOqkQ70PsJ"
   },
   "source": [
    "In dem `labels_`-Feld stehen dir jetzt die entdecken Cluster zur Verfügung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_2FLlOc0PsJ"
   },
   "outputs": [],
   "source": [
    "km5.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgeQUJRj0PsK"
   },
   "source": [
    "Schau dir zum Vergleich die echten Varianten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCPN3Pd60PsK"
   },
   "outputs": [],
   "source": [
    "iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWSfYFCB0PsK"
   },
   "source": [
    "Die Zahlen sind beliebig. Am Anfang hat es noch ganz gut geklappt - aber dann gibt es schon ein ziemliches Durcheinander!\n",
    "\n",
    "Oben hattet du gesehen, dass sich die Iris-Varianten am besten durch die *Petal Length* vs. *Sepal Length* unterscheiden lassen. Mit `seaborn` kannst du einen Scatter-Plot zeichnen lassen und sowohl die Marker als auch die Farben beeinflussen. Wenn du die Marker auf die echte Spezies setzt und die Farben auf die Cluster, siehst du, was nicht richtig gelöst wurde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPQFeaZt0PsK"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.scatterplot(x=idf[\"Sepal Length\"], y=idf[\"Petal Length\"], hue=idf[\"name\"], style=km5.labels_, \n",
    "                s=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdjcoKgm0PsK"
   },
   "source": [
    "Versuch es nochmal mit der richtigen Anzahl der Cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHq7dlFF0PsK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "km3 = KMeans(n_clusters=3)\n",
    "km3.fit(iris['data'])\n",
    "km3.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E0qLwyE0PsL"
   },
   "source": [
    "Das Ergebnis sieht jetzt auch optisch sehr viel besser aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC3tXnHO0PsL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.scatterplot(x=idf[\"Sepal Length\"], y=idf[\"Petal Length\"], hue=km3.labels_, style=idf[\"name\"], \n",
    "                s=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpXdUbrH0PsL"
   },
   "source": [
    "Ein Clusterverfahren wie `MeanShift` ermittelt die Anzahl der Cluster selbstständig:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goL6CAIs0PsL"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "ms = MeanShift()\n",
    "ms.fit(iris['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uEWCvxV0PsL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.scatterplot(x=idf[\"Sepal Length\"], y=idf[\"Petal Length\"], hue=ms.labels_, style=idf[\"name\"], \n",
    "                s=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUcQJb020PsM"
   },
   "source": [
    "Mithilfe des Silhouette-Scores kannst du ermitteln, wie gut das Clustering (für *konvexe Cluster*) funktioniert hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhKRS3Do0PsM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(iris['data'], km3.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFxKg-n20PsM"
   },
   "outputs": [],
   "source": [
    "silhouette_score(iris['data'], km5.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DKxmtlj0PsM"
   },
   "outputs": [],
   "source": [
    "silhouette_score(iris['data'], ms.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEngxTdz0PsM"
   },
   "source": [
    "Innerhalb des gleichen Cluster-Verfahrens kannst du den Silhouette-Score gut vergleichen. `MeanShift` hat nach dem Bild oben natürlich auch gute Argument, warum es nur zwei Cluster gefunden hat. Vermutliche sind sich Spezies in dem \"oberen\" Cluster auch deutlich ähnlicher!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfzVtROf0PsN"
   },
   "source": [
    "### Reddit-Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKiLnQMj0PsN"
   },
   "source": [
    "Topic-Modelle kann `scikit-learn` mit mehreren Methoden berechnen. `NMF` ist deutlich schneller als `LDA` und hat häufig ebenso gute Ergebnisse.\n",
    "\n",
    "Die Aufrufe sind sehr ähnlich zum Clustering und zur Klassifikation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f reddit-technology-toplevel-title.csv.xz || wget  https://github.com/heiseacademy/ml-python/raw/main/02-ml-intro/reddit-technology-toplevel-title.csv.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HuPGQO20Pry"
   },
   "outputs": [],
   "source": [
    "docs = pd.read_csv(\"reddit-technology-toplevel-title.csv.xz\", parse_dates=[\"created_utc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= {\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', \n",
    "             'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', \n",
    "             'amongst', 'amount', 'amp', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', \n",
    "             'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', \n",
    "             'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', \n",
    "             'beyond', 'blog', 'body', 'both', 'bottom', 'but', 'buy', 'buycheap', 'by', 'ca', 'call', 'can', 'cannot', \n",
    "             'case', 'change', 'co', 'com', 'could', 'create', 'delete', 'did', 'do', 'does', 'doing', 'done', 'down', \n",
    "             'download', 'drive', 'due', 'during', 'each', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'email', \n",
    "             'empty', 'enough', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', \n",
    "             'fifteen', 'fifty', 'first', 'five', 'fix', 'for', 'former', 'formerly', 'forty', 'four', 'from', 'front', \n",
    "             'full', 'further', 'get', 'give', 'go', 'good', 'had', 'has', 'have', 'he', 'help', 'hence', 'her', 'here', \n",
    "             'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', \n",
    "             'http', 'https', 'hundred', 'i', 'if', 'in', 'indeed', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', \n",
    "             'last', 'late', 'latter', 'latterly', 'least', 'less', 'll', 'look', 'made', 'make', 'many', 'market', 'may', \n",
    "             'me', 'meanwhile', 'message', 'might', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', \n",
    "             'must', 'my', 'myself', \"n't\", 'name', 'namely', 'need', 'neither', 'never', 'nevertheless', 'new', 'news', \n",
    "             'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'number', 'n‘t', \n",
    "             'n’t', 'of', 'off', 'often', 'on', 'once', 'one', 'online', 'only', 'onto', 'or', 'other', 'others', \n",
    "             'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'page', 'part', 'pass', 'per', 'perhaps', \n",
    "             'please', 'post', 'put', 'question', 'quite', 'rather', 're', 'really', 'reddit', 'regarding', 'remove', \n",
    "             'review', 'same', 'say', 'search', 'see', 'seem', 'seemed', 'seeming', 'seems', 'self', 'send', 'serious', \n",
    "             'several', 'she', 'should', 'show', 'side', 'since', 'site', 'six', 'sixty', 'so', 'some', 'somehow', \n",
    "             'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'support', 'take', 'ten', \n",
    "             'test', 'text', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', \n",
    "             'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'third', 'this', 'those', \n",
    "             'though', 'three', 'through', 'throughout', 'thru', 'thus', 'time', 'to', 'together', 'too', 'top', \n",
    "             'toward', 'towards', 'twelve', 'twenty', 'two', 'under', 'unless', 'unlock', 'until', 'up', 'upon', \n",
    "             'us', 'use', 'used', 'using', 'various', 've', 'very', 'via', 'video', 'was', 'watch', 'way', 'we', 'well', \n",
    "             'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', \n",
    "             'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', \n",
    "             'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'work', 'would', 'yet', 'you', 'your', \n",
    "             'yours', 'yourself', 'yourselves', '‘d', '‘ll', '‘m', '‘re', '‘s', '‘ve', '’d', '’ll', '’m', '’re', \n",
    "             '’s', '’ve'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=10, stop_words=list(stop_words))\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(docs[\"title\"].map(str))\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-nT5nwP0PsN"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "nmf = NMF(n_components = num_topics)\n",
    "nmf.fit(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBQoVSGA0PsN"
   },
   "source": [
    "Um die Ergebnisse darzustellen, wollen wir Wordclouds benutzen. Dazu berechnest du die wichtigsten Wörter in jedem einzelnen Topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yq5G4Hk90PsO"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def wordcloud_topic_model_summary(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        freq = { feature_names[i]: topic[i] for i in topic.argsort()[:-no_top_words - 1:-1] }\n",
    "        wc = WordCloud(background_color=\"white\", max_words=100, width=960, height=540)\n",
    "        wc.generate_from_frequencies(freq)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(wc, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRV8KB3d0PsO"
   },
   "outputs": [],
   "source": [
    "wordcloud_topic_model_summary(nmf, tfidf_vectorizer.get_feature_names_out(), 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKGtsyaJ0PsO"
   },
   "source": [
    "Das Ergebnis ist gut interpretierbar und vor allem *unvoreingenommen*. Mit wenigen Zeilen Code hast du so die Themen in zwei Millionen Posts bestimmt!\n",
    "\n",
    "Die Anzahl der Topics kannst du variieren und sehen, ob du damit bessere Ergebnisse erzielen kannst. Es gibt auch Scores, mit denen du die Güte ermitteln kannst (Coherence Score oder Perlexity)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML Python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
